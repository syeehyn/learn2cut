{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:02:16.255100Z",
     "start_time": "2021-04-14T22:02:16.095312Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from gymenv_v2 import make_multiple_env\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:02:16.266156Z",
     "start_time": "2021-04-14T22:02:16.257219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training instances, dir ../instances/train_10_n60_m60 idx 0\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 1\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 2\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 3\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 4\n"
     ]
    }
   ],
   "source": [
    "easy_config = {\n",
    "    \"load_dir\"        : '../instances/train_10_n60_m60',\n",
    "    \"idx_list\"        : list(range(5)),\n",
    "    \"timelimit\"       : 20,\n",
    "    \"reward_type\"     : 'obj'\n",
    "}\n",
    "env = make_multiple_env(**easy_config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:02:16.612160Z",
     "start_time": "2021-04-14T22:02:16.268532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available? %s. False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Is CUDA available? %s.\", use_cuda)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:02:16.618175Z",
     "start_time": "2021-04-14T22:02:16.615853Z"
    }
   },
   "outputs": [],
   "source": [
    "# class policyNet(nn.Module):\n",
    "#     def __init__(self, size_dim, hidden):\n",
    "#         super(policyNet, self).__init__()\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.fc1 = nn.Linear(size_dim, hidden)\n",
    "#     def forward(self, s):\n",
    "#         A, b, _, E, d = self._preproc(s)\n",
    "#         Ab = torch.hstack((A, b.unsqueeze(1)))\n",
    "#         Ed = torch.hstack((E, d.unsqueeze(1)))\n",
    "#         h = F.relu(self.fc1(Ab))\n",
    "#         g = F.relu(self.fc1(Ed))\n",
    "#         return torch.nn.functional.softmax((h @ g.T).mean(0), dim=-1)\n",
    "#     def _preproc(self, s):\n",
    "#         min1 = min(s[0].min(), s[-2].min())\n",
    "#         max1 = max(s[0].max(), s[-2].max())\n",
    "#         min2 = min(s[1].min(), s[-1].min())\n",
    "#         max2 = max(s[1].max(), s[-1].max())\n",
    "\n",
    "#         A = torch.FloatTensor((s[0] - min1) / (max1 - min1))\n",
    "#         E = torch.FloatTensor((s[-2] - min1) / (max1 - min1))\n",
    "#         b = torch.FloatTensor((s[1] - min2) / (max2 - min2))\n",
    "#         d = torch.FloatTensor((s[-1] - min2) / (max2 - min2))\n",
    "#         return [A, b, torch.LongTensor(s[2]), E, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:02:16.805053Z",
     "start_time": "2021-04-14T22:02:16.793544Z"
    }
   },
   "outputs": [],
   "source": [
    "class policyNet(nn.Module):\n",
    "    def __init__(self, size_dim, hidden_size, output_size):\n",
    "        super(policyNet, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(size_dim, hidden_size, batch_first=True)\n",
    "        \n",
    "        self.hidden_combine = nn.Linear(hidden_size*2, hidden_size)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        \n",
    "#         self.fc1 = nn.Linear(size_dim, hidden)\n",
    "    def forward(self, s, hidden):\n",
    "        A, b, _, E, d = self._preproc(s)\n",
    "        Ab = torch.hstack((A, b.unsqueeze(1)))\n",
    "        Ed = torch.hstack((E, d.unsqueeze(1)))\n",
    "        \n",
    "        h, h_hidden = self.gru(Ab.unsqueeze(0), hidden.unsqueeze(0))\n",
    "        \n",
    "        g, g_hidden = self.gru(Ed.unsqueeze(0), hidden.unsqueeze(0))\n",
    "        \n",
    "        h = self.out(h.squeeze(0))\n",
    "        g = self.out(g.squeeze(0))\n",
    "        \n",
    "        hidden = torch.cat((h_hidden.squeeze(0), g_hidden.squeeze(0)), 1)\n",
    "        \n",
    "        hidden = self.hidden_combine(F.relu(hidden))\n",
    "        \n",
    "        S = torch.mean(h @ g.T, 0)\n",
    "        \n",
    "        return F.log_softmax(S, dim=-1), hidden\n",
    "        \n",
    "        \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size, device=device)\n",
    "        \n",
    "        \n",
    "        return torch.nn.functional.softmax((h @ g.T).mean(0), dim=-1)\n",
    "    def _preproc(self, s):\n",
    "        min1 = min(s[0].min(), s[-2].min())\n",
    "        max1 = max(s[0].max(), s[-2].max())\n",
    "        min2 = min(s[1].min(), s[-1].min())\n",
    "        max2 = max(s[1].max(), s[-1].max())\n",
    "\n",
    "        A = torch.FloatTensor((s[0] - min1) / (max1 - min1))\n",
    "        E = torch.FloatTensor((s[-2] - min1) / (max1 - min1))\n",
    "        b = torch.FloatTensor((s[1] - min2) / (max2 - min2))\n",
    "        d = torch.FloatTensor((s[-1] - min2) / (max2 - min2))\n",
    "        return [A, b, torch.LongTensor(s[2]), E, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:02:18.695475Z",
     "start_time": "2021-04-14T22:02:18.685489Z"
    }
   },
   "outputs": [],
   "source": [
    "class valueNet(nn.Module):\n",
    "    def __init__(self, size_dim, hidden_size):\n",
    "        super(valueNet, self).__init__()\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "                            nn.Linear(size_dim, hidden_size),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(hidden_size, 1)\n",
    "                        )\n",
    "        \n",
    "        \n",
    "#         self.fc1 = nn.Linear(size_dim, hidden)\n",
    "    def forward(self, s):\n",
    "        A, b, _, E, d = self._preproc(s)\n",
    "        Ab = torch.hstack((A, b.unsqueeze(1)))\n",
    "        Ed = torch.hstack((E, d.unsqueeze(1)))\n",
    "        \n",
    "        Ab = self.mlp(Ab)\n",
    "        Ed = self.mlp(Ed)\n",
    "        v = Ab @ Ed.T\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return v.mean()\n",
    "    def _preproc(self, s):\n",
    "        min1 = min(s[0].min(), s[-2].min())\n",
    "        max1 = max(s[0].max(), s[-2].max())\n",
    "        min2 = min(s[1].min(), s[-1].min())\n",
    "        max2 = max(s[1].max(), s[-1].max())\n",
    "\n",
    "        A = torch.FloatTensor((s[0] - min1) / (max1 - min1))\n",
    "        E = torch.FloatTensor((s[-2] - min1) / (max1 - min1))\n",
    "        b = torch.FloatTensor((s[1] - min2) / (max2 - min2))\n",
    "        d = torch.FloatTensor((s[-1] - min2) / (max2 - min2))\n",
    "        return [A, b, torch.LongTensor(s[2]), E, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T06:35:02.450022Z",
     "start_time": "2021-04-14T06:35:02.446944Z"
    }
   },
   "outputs": [],
   "source": [
    "model = valueNet(61, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T06:35:02.655451Z",
     "start_time": "2021-04-14T06:35:02.652484Z"
    }
   },
   "outputs": [],
   "source": [
    "prob = model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T06:36:20.830110Z",
     "start_time": "2021-04-14T06:36:20.826093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0160, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:02:20.580517Z",
     "start_time": "2021-04-14T22:02:20.576257Z"
    }
   },
   "outputs": [],
   "source": [
    "def discounted_rewards(r, gamma):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_sum = 0\n",
    "    for i in reversed(range(0,len(r))):\n",
    "        discounted_r[i] = running_sum * gamma + r[i]\n",
    "        running_sum = discounted_r[i]\n",
    "    return torch.FloatTensor(discounted_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T22:02:22.797454Z",
     "start_time": "2021-04-14T22:02:20.858242Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mieor-4575\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.26 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.13<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">sweet-sky-1423</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ieor-4575/finalproject\" target=\"_blank\">https://wandb.ai/ieor-4575/finalproject</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ieor-4575/finalproject/runs/3hcw8hv7\" target=\"_blank\">https://wandb.ai/ieor-4575/finalproject/runs/3hcw8hv7</a><br/>\n",
       "                Run data is saved locally in <code>/Users/syeehyn/Desktop/spring2020/ieor4575/project/learn2cut/dev/wandb/run-20210414_180221-3hcw8hv7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "run=wandb.init(project=\"finalproject\", entity=\"ieor-4575\", tags=[\"training-easy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T23:17:05.424584Z",
     "start_time": "2021-04-14T22:02:35.831662Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://wandb.ai/ieor-4575/finalproject/runs/3hcw8hv7?jupyter=true\" style=\"border:none;width:100%;height:420px\">\n",
       "                </iframe>"
      ],
      "text/plain": [
       "<wandb.jupyter.Run at 0x7f99a0ab4ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training instances, dir ../instances/train_10_n60_m60 idx 0\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 1\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 2\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 3\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 4\n",
      "Academic license - for non-commercial use only - expires 2021-06-11\n",
      "Using license file /Users/syeehyn/gurobi.lic\n",
      "loss: 23.54226605947031\n",
      "loss: 5.632691727984122\n",
      "loss: 15.721467907607288\n",
      "loss: 16.82992080896428\n",
      "loss: 15.704037272061196\n",
      "loss: 13.999904044466424\n",
      "loss: 16.17121589852538\n",
      "loss: 13.491036759713854\n",
      "loss: 15.981016398963593\n",
      "loss: 18.397643527935525\n",
      "loss: 14.249286262798071\n",
      "loss: 11.824086581209995\n",
      "loss: 12.252815492987883\n",
      "loss: 13.527673859336778\n",
      "loss: 14.906833908933908\n",
      "loss: 14.027847617973752\n",
      "loss: 12.457113485721372\n",
      "loss: 14.32559438448978\n",
      "loss: 16.137384164303807\n",
      "loss: 13.15301636256126\n"
     ]
    }
   ],
   "source": [
    "%%wandb\n",
    "env = make_multiple_env(**easy_config)\n",
    "N = 60\n",
    "\n",
    "alpha = 1e-1\n",
    "beta = 1e-3\n",
    "\n",
    "numtrajs = 32\n",
    "iterations = 20\n",
    "gamma = .8\n",
    "\n",
    "\n",
    "# criterion = torch.nn.SmoothL1Loss(size_average=False)\n",
    "\n",
    "\n",
    "\n",
    "policy = policyNet(N+1, 128, 64)\n",
    "\n",
    "value_function = valueNet(N+1, 128)\n",
    "\n",
    "hidden = policy.initHidden()\n",
    "\n",
    "\n",
    "value_optimizer = torch.optim.Adam(value_function.parameters(), lr=beta)\n",
    "value_scheduler = torch.optim.lr_scheduler.ExponentialLR(value_optimizer, gamma=0.99)\n",
    "\n",
    "policy_optimizer = torch.optim.Adam(policy.parameters(), lr=alpha)\n",
    "policy_scheduler = torch.optim.lr_scheduler.ExponentialLR(policy_optimizer, gamma=0.99)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rrecord = []\n",
    "for ite in range(iterations):\n",
    "    \n",
    "    OBS = []\n",
    "    ACTS = []\n",
    "    VALS = []\n",
    "    \n",
    "    for num in range(numtrajs):\n",
    "        obss = []\n",
    "        acts = []\n",
    "        rews = []\n",
    "\n",
    "\n",
    "        s = env.reset()\n",
    "        d = False\n",
    "        repisode = 0\n",
    "        while not d:\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prob, _ = policy(s, hidden)\n",
    "                prob /= prob.sum()\n",
    "\n",
    "            a = np.random.choice(s[-1].size, p = prob.numpy(), size=1)\n",
    "\n",
    "            obss.append(s)\n",
    "\n",
    "            s, r, d, _ = env.step(list(a))\n",
    "\n",
    "\n",
    "            acts.append(a)\n",
    "            rews.append(r)\n",
    "\n",
    "            repisode += r\n",
    "\n",
    "        rrecord.append(np.sum(rews))\n",
    "\n",
    "        v_hat = discounted_rewards(rews, gamma)\n",
    "        \n",
    "        OBS.append(obss)\n",
    "        ACTS.append(acts)\n",
    "        VALS.append(v_hat)\n",
    "    \n",
    "    \n",
    "#     criterion = []\n",
    "    \n",
    "#     for obss, v_hat in zip(OBS, VALS):\n",
    "#         for obs, v in zip(obss, v_hat):\n",
    "#             v_ = value_function(obs)\n",
    "#             loss = torch.square(v_ - v)\n",
    "#             value_optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             value_optimizer.step()\n",
    "#             value_scheduler.step()\n",
    "#             criterion.append(loss.item())\n",
    "#     print(f'value approx loss: {np.mean(criterion)}')\n",
    "    \n",
    "#     ADS = []\n",
    "#     with torch.no_grad():\n",
    "#         for obss, v_hat in zip(OBS, VALS):\n",
    "#             ads = []\n",
    "#             for obs, v in zip(obss, v_hat):\n",
    "#                 v_ = value_function(obs)\n",
    "#                 ads.append(v - v_)\n",
    "#             ADS.append(torch.FloatTensor(ads))\n",
    "    \n",
    "    \n",
    "    criterion = []\n",
    "    for obss, acts, v_hat in zip(OBS, ACTS, VALS):\n",
    "        for obs, act, v in zip(obss, acts, v_hat):\n",
    "            prob, hidden = policy(obs, hidden)\n",
    "            prob_selected = prob[act]\n",
    "            hidden = hidden.detach()\n",
    "            loss = - v * prob_selected\n",
    "\n",
    "            policy_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            policy_optimizer.step()\n",
    "            policy_scheduler.step()\n",
    "            criterion.append(loss.item())\n",
    "        \n",
    "    print(f'loss: {np.mean(criterion)}')\n",
    "    \n",
    "#     fixedWindow=100\n",
    "#     movingAverage=0\n",
    "#     if len(rrecord) >= fixedWindow:\n",
    "#         movingAverage=np.mean(rrecord[len(rrecord)-fixedWindow:len(rrecord)-1])\n",
    "        \n",
    "    #wandb logging\n",
    "    wandb.log({ \"Training reward\" : rrecord[-1]})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-14T21:49:08.013Z"
    }
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/IPython/core/events.py\u001b[0m in \u001b[0;36mtrigger\u001b[0;34m(self, event, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures)\u001b[0m\n\u001b[1;32m   2978\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pre_execute'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pre_run_cell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m         \u001b[0;31m# If any of our input transformation (input_transformer_manager or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/IPython/core/events.py\u001b[0m in \u001b[0;36mtrigger\u001b[0;34m(self, event, *args, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error in callback {} (for {}):\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/wandb/sdk/lib/redirect.py\u001b[0m in \u001b[0;36mnew_write\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mnew_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0mold_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_console_callback\u001b[0;34m(self, name, data)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_console_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;31m# logger.info(\"console callback: %s, %s\", name, data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_tensorboard_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_logdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_output\u001b[0;34m(self, name, data)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb_internal_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutputRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0motype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetCurrentTime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish_output\u001b[0;34m(self, outdata)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb_internal_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_tbdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_logdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ieor4575/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    }
   ],
   "source": [
    "prob, _ = policy(s, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ieor4575]",
   "language": "python",
   "name": "conda-env-ieor4575-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
