{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T18:32:30.252440Z",
     "start_time": "2021-04-13T18:32:30.249886Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T18:32:31.125792Z",
     "start_time": "2021-04-13T18:32:30.940578Z"
    }
   },
   "outputs": [],
   "source": [
    "from gymenv_v2 import make_multiple_env\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T23:38:43.343072Z",
     "start_time": "2021-04-13T23:38:43.338995Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_config = {\n",
    "    \"load_dir\"        : '../instances/randomip_n60_m60',   # this is the location of the randomly generated instances (you may specify a different directory)\n",
    "    \"idx_list\"        : list(range(20)),                # take the first 20 instances from the directory\n",
    "    \"timelimit\"       : 50,                             # the maximum horizon length is 50\n",
    "    \"reward_type\"     : 'obj'                           # DO NOT CHANGE reward_type\n",
    "}\n",
    "\n",
    "# Easy Setup: Use the following environment settings. We will evaluate your agent with the same easy config below:\n",
    "easy_config = {\n",
    "    \"load_dir\"        : '../instances/train_10_n60_m60',\n",
    "    \"idx_list\"        : list(range(10)),\n",
    "    \"timelimit\"       : 50,\n",
    "    \"reward_type\"     : 'obj'\n",
    "}\n",
    "\n",
    "# Hard Setup: Use the following environment settings. We will evaluate your agent with the same hard config below:\n",
    "hard_config = {\n",
    "    \"load_dir\"        : '../instances/train_100_n60_m60',\n",
    "    \"idx_list\"        : list(range(99)),\n",
    "    \"timelimit\"       : 50,\n",
    "    \"reward_type\"     : 'obj'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s[0]: constraint matrix $A$of the current LP ($\\max -c^Tx \\text{ s.t. }Ax \\le b$) . Dimension is $m \\times n$. See by printing s[0].shape. Here $n$ is the (fixed) number of variables. For instances of size 60 by 60 used in the above command, $n$ will remain fixed as 60. And $m$ is the current number of constraints. Initially, $m$ is to the number of constraints in the IP instance. (For instances generated with --num-c=60, $m$ is 60 at the first step). But $m$ will increase by one in every step of the episode as one new constraint (cut) is added on taking an action.\n",
    "\n",
    "s[1]: rhs $b$ for the current LP ($Ax\\le b$). Dimension same as the number $m$ in matrix A.\n",
    "\n",
    "s[2]: coefficient vector $c$ from the LP objective ($-c^Tx$). Dimension same as the number of variables, i.e., $n$.\n",
    "\n",
    "s[3], s[4]: Gomory cuts available in the current round of Gomory's cutting plane algorithm. Each cut $i$ is of the form $D_i x\\le d_i$. s[3] gives the matrix $D$ (of dimension $k \\times n$) of cuts and s[4] gives the rhs $d$ (of dimension $k$). The number of cuts $k$ available in each round changes, you can find it out by printing the size of last component of state, i.e., s[4].size or s[-1].size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T23:38:54.004964Z",
     "start_time": "2021-04-13T23:38:53.988749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training instances, dir ../instances/train_10_n60_m60 idx 0\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 1\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 2\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 3\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 4\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 5\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 6\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 7\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 8\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 9\n"
     ]
    }
   ],
   "source": [
    "env = make_multiple_env(**easy_config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-12T17:43:31.396981Z",
     "start_time": "2021-04-12T17:43:28.231545Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# s = env.reset()   # samples a random instance every time env.reset() is called\n",
    "# d = False\n",
    "# t = 0\n",
    "# repisode = 0\n",
    "# for e in range(20):\n",
    "#     # gym loop\n",
    "#     s = env.reset()   # samples a random instance every time env.reset() is called\n",
    "#     d = False\n",
    "#     t = 0\n",
    "#     repisode = 0\n",
    "\n",
    "#     while not d:\n",
    "#         a = np.random.randint(0, s[-1].size, 1)            # s[-1].size shows the number of actions, i.e., cuts available at state s\n",
    "#         s, r, d, _ = env.step(list(a))\n",
    "#         print('episode', e, 'step', t, 'reward', r, 'action space size', s[-1].size, 'action', a[0])\n",
    "\n",
    "#         A, b, c0, cuts_a, cuts_b = s\n",
    "#         print(A.shape, b.shape, c0.shape, cuts_a.shape, cuts_b.shape)\n",
    "\n",
    "#         t += 1\n",
    "#         repisode += r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T18:32:37.792114Z",
     "start_time": "2021-04-13T18:32:37.355961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available? %s. False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Is CUDA available? %s.\", use_cuda)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T18:32:43.481108Z",
     "start_time": "2021-04-13T18:32:43.478512Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T18:32:44.306525Z",
     "start_time": "2021-04-13T18:32:44.303394Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T18:32:44.722194Z",
     "start_time": "2021-04-13T18:32:44.719956Z"
    }
   },
   "outputs": [],
   "source": [
    "gamma = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T19:29:11.003329Z",
     "start_time": "2021-04-13T19:29:09.936230Z"
    }
   },
   "outputs": [],
   "source": [
    "s = env.reset()   # samples a random instance every time env.reset() is called\n",
    "d = False\n",
    "t = 0\n",
    "repisode = 0\n",
    "\n",
    "\n",
    "ABs = []\n",
    "EDs = []\n",
    "\n",
    "acts = []   # actions\n",
    "rews = []  # instant rewards\n",
    "obs = env.reset()\n",
    "done = False\n",
    "\n",
    "for _ in range(3):\n",
    "    a = np.random.randint(0, s[-1].size, 1)\n",
    "    ABs.append(preproc_ab(s[0], s[1]))\n",
    "    EDs.append(preproc_ab(s[3], s[4]))\n",
    "    \n",
    "    s, r, d, _ = env.step(list(a))\n",
    "    A, b, c0, cuts_a, cuts_b = s\n",
    "    acts.append(s[-1])\n",
    "    rews.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T19:14:27.480635Z",
     "start_time": "2021-04-13T19:14:27.477644Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-13T18:32:48.974086Z",
     "start_time": "2021-04-13T18:32:48.969730Z"
    }
   },
   "outputs": [],
   "source": [
    "def discounted_rewards(r, gamma):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_sum = 0\n",
    "    for i in reversed(range(0,len(r))):\n",
    "        discounted_r[i] = running_sum * gamma + r[i]\n",
    "        running_sum = discounted_r[i]\n",
    "    return torch.FloatTensor(discounted_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T01:48:32.513996Z",
     "start_time": "2021-04-14T01:48:32.509039Z"
    }
   },
   "outputs": [],
   "source": [
    "class policyNet(nn.Module):\n",
    "    def __init__(self, size_dim, hidden):\n",
    "        super(policyNet, self).__init__()\n",
    "        self.size_dim = size_dim\n",
    "        self.fc1 = nn.Linear(size_dim, hidden)\n",
    "        \n",
    "    def forward(self, ab, ed):\n",
    "        batch_size = ab.shape[0]\n",
    "        h = F.relu(self.fc1(ab))\n",
    "        g = F.relu(self.fc1(ed))\n",
    "        g = torch.transpose(g, 1, 2)\n",
    "        \n",
    "        S = torch.mean(torch.bmm(h, g),1)\n",
    "        return S\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T02:04:31.586464Z",
     "start_time": "2021-04-14T02:04:31.577927Z"
    }
   },
   "outputs": [],
   "source": [
    "class policyNet(nn.Module):\n",
    "    def __init__(self, size_dim, lstm_hidden):\n",
    "        super(policyNet, self).__init__()\n",
    "        self.size_dim = size_dim\n",
    "        self.lstm_hidden = lstm_hidden\n",
    "        self.LSTM = nn.LSTM(input_size=size_dim, \n",
    "                            hidden_size=lstm_hidden, \n",
    "                            batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=lstm_hidden,\n",
    "                           out_features=size_dim)\n",
    "        \n",
    "    def forward(self, ab, ed):\n",
    "        batch_size = ab.shape[0]\n",
    "        ab, _ = self.LSTM(ab)\n",
    "        h = F.relu(self.fc1(ab))\n",
    "        ed, (hidden, _) = self.LSTM(ed)\n",
    "        g = F.relu(self.fc1(ed))\n",
    "        g = torch.transpose(g, 1, 2)\n",
    "        S = torch.mean(torch.bmm(h, g),1)\n",
    "        return S\n",
    "    \n",
    "    \n",
    "class valueNetwork(nn.Module):\n",
    "    def __init__(self, size_dim, lstm_hidden):\n",
    "        super(valueNetwork, self).__init__()\n",
    "        self.size_dim = size_dim\n",
    "        self.lstm_hidden = lstm_hidden\n",
    "        self.LSTM = nn.LSTM(input_size=size_dim, \n",
    "                            hidden_size=lstm_hidden, \n",
    "                            batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=lstm_hidden,\n",
    "                           out_features=1)\n",
    "        \n",
    "    def forward(self, ab, ed):\n",
    "        _, _ = self.LSTM(ab)\n",
    "        _, (hidden, _) = self.LSTM(ed)\n",
    "        \n",
    "        hidden = F.relu(hidden.squeeze())\n",
    "        output = self.fc1(hidden)\n",
    "        \n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T02:05:38.904644Z",
     "start_time": "2021-04-14T02:05:38.897590Z"
    }
   },
   "outputs": [],
   "source": [
    "class policyNet(nn.Module):\n",
    "    def __init__(self, size_dim, hidden):\n",
    "        super(policyNet, self).__init__()\n",
    "        self.size_dim = size_dim\n",
    "        self.fc1 = nn.Linear(size_dim, hidden)\n",
    "        \n",
    "    def forward(self, ab, ed):\n",
    "        batch_size = ab.shape[0]\n",
    "        h = F.relu(self.fc1(ab))\n",
    "        g = F.relu(self.fc1(ed))\n",
    "        g = torch.transpose(g, 1, 2)\n",
    "        \n",
    "        S = torch.mean(torch.bmm(h, g),1)\n",
    "        return S\n",
    "\n",
    "class valueNetwork(nn.Module):\n",
    "    def __init__(self, size_dim, hidden):\n",
    "        super(valueNetwork, self).__init__()\n",
    "        self.size_dim = size_dim\n",
    "        self.fc1 = nn.Linear(size_dim, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, 1)\n",
    "    def forward(self, ab, ed):\n",
    "        batch_size = ab.shape[0]\n",
    "        h = F.relu(self.fc1(ab))\n",
    "        g = F.relu(self.fc1(ed))\n",
    "        g = torch.transpose(g, 1, 2)\n",
    "        J = torch.mean(torch.bmm(h, g),1)\n",
    "        \n",
    "        return J.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T03:15:22.552718Z",
     "start_time": "2021-04-14T03:15:22.547548Z"
    }
   },
   "outputs": [],
   "source": [
    "model = valueNetwork(61, 64)\n",
    "a = As[0]\n",
    "b = Bs[0]\n",
    "ab = torch.cat((a, b.unsqueeze(-1)), dim=-1)\n",
    "e = Es[0]\n",
    "d = Ds[0]\n",
    "ed = torch.cat((e, d.unsqueeze(-1)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T03:15:31.248729Z",
     "start_time": "2021-04-14T03:15:31.245851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 109, 61])"
      ]
     },
     "execution_count": 808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T03:15:11.998274Z",
     "start_time": "2021-04-14T03:15:11.987634Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ValueFunction(object):\n",
    "    \n",
    "    def __init__(self, size_dim, lstm_hidden, lr):\n",
    "        \n",
    "        self.model = valueNetwork(size_dim + 1, lstm_hidden)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "        \n",
    "    def compute_values(self, ab ,ed):\n",
    "        with torch.no_grad():\n",
    "            return self.model(ab, ed)\n",
    "    \n",
    "    def train(self, ab, ed, targets):\n",
    "        \n",
    "        v_preds = self.model(ab, ed)\n",
    "        \n",
    "        loss = torch.nn.functional.smooth_l1_loss(v_preds, targets)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # UPDATE\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    \n",
    "\n",
    "class Policy(object):\n",
    "    \n",
    "    def __init__(self, size_dim, lstm_hidden, lr):\n",
    "        self.model = policyNet(size_dim + 1, lstm_hidden)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.99)\n",
    "        \n",
    "    def compute_prob(self, ab, ed):\n",
    "        with torch.no_grad():\n",
    "            prob = self.model(ab, ed)\n",
    "            return prob\n",
    "    \n",
    "    def train(self, ab, ed, actions, Qs):\n",
    "        logits = self.model(ab, ed)\n",
    "        prob = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        \n",
    "        prob_selected = prob.gather(-1, acts).squeeze()\n",
    "        prob_selected += 1e-8\n",
    "        \n",
    "        loss = -torch.mean(Qs * torch.log(prob_selected))\n",
    "        \n",
    "        \n",
    "        \n",
    "        # BACKWARD PASS\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # UPDATE\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "        return loss.item()  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T03:15:14.003052Z",
     "start_time": "2021-04-14T03:15:13.996678Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _preproc(s):\n",
    "    min1 = min(s[0].min(), s[-2].min())\n",
    "    max1 = max(s[0].max(), s[-2].max())\n",
    "    min2 = min(s[1].min(), s[-1].min())\n",
    "    max2 = max(s[1].max(), s[-1].max())\n",
    "    \n",
    "    A = torch.FloatTensor((s[0] - min1) / (max1 - min1))\n",
    "    E = torch.FloatTensor((s[-2] - min1) / (max1 - min1))\n",
    "    b = torch.FloatTensor((s[1] - min2) / (max2 - min2))\n",
    "    d = torch.FloatTensor((s[-1] - min2) / (max2 - min2))\n",
    "    \n",
    "    return [A, b, torch.LongTensor(s[2]), E, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-14T03:11:36.297498Z",
     "start_time": "2021-04-14T03:11:09.492933Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training instances, dir ../instances/train_10_n60_m60 idx 0\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 1\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 2\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 3\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 4\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 5\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 6\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 7\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 8\n",
      "loading training instances, dir ../instances/train_10_n60_m60 idx 9\n",
      "error in lp iteration\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-801-29ca6ca6a30e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mrews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/spring2020/ieor4575/project/learn2cut/gymenv_v2.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_now\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_now\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/spring2020/ieor4575/project/learn2cut/gymenv_v2.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/spring2020/ieor4575/project/learn2cut/gymenv_v2.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/spring2020/ieor4575/project/learn2cut/gymenv_v2.py\u001b[0m in \u001b[0;36m_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuts_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuts_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuts_a\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuts_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/spring2020/ieor4575/project/learn2cut/gymenv_v2.py\u001b[0m in \u001b[0;36mcompute_state\u001b[0;34m(A, b, c)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mc_tilde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSOLVER\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GUROBI'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbasis_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGurobiSolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_tilde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_tilde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_tilde\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mSOLVER\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SCIPY'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbasis_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScipyLinProgSolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_tilde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb_tilde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_tilde\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/spring2020/ieor4575/project/learn2cut/gurobiutils.py\u001b[0m in \u001b[0;36mGurobiSolve\u001b[0;34m(A, b, c, Method)\u001b[0m\n\u001b[1;32m     33\u001b[0m                  \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                  name=\"X\")\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvarrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethod\u001b[0m \u001b[0;31m# primal simplex Method = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print('start optimizing...')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/gurobipy/model.pxi\u001b[0m in \u001b[0;36mgurobipy.Model.addConstrs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/Desktop/spring2020/ieor4575/project/learn2cut/gurobiutils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m                  \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                  name=\"X\")\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvarrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethod\u001b[0m \u001b[0;31m# primal simplex Method = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print('start optimizing...')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/spring2020/ieor4575/project/learn2cut/gurobiutils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m                  \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                  name=\"X\")\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddConstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvarrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMethod\u001b[0m \u001b[0;31m# primal simplex Method = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print('start optimizing...')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = make_multiple_env(**easy_config)\n",
    "N = 60\n",
    "\n",
    "\n",
    "lstm_hidden_size = 64\n",
    "alpha = 1e-2\n",
    "beta = 1e-2\n",
    "numtrajs = 5\n",
    "iterations = 20\n",
    "gamma = .8\n",
    "\n",
    "policy = Policy(N, 64, alpha)\n",
    "baseline = ValueFunction(N, 64, beta)\n",
    "\n",
    "rrecord = []\n",
    "\n",
    "for ite in range(iterations):\n",
    "    \n",
    "    \n",
    "    t = 0\n",
    "    repisode = 0\n",
    "    \n",
    "    As = []\n",
    "    Bs = []\n",
    "    Cs = []\n",
    "    Es = []\n",
    "    Ds = []\n",
    "    \n",
    "    \n",
    "    ACTs = []\n",
    "    VAL = []\n",
    "    \n",
    "    for num in range(numtrajs):\n",
    "        \n",
    "        obss = []\n",
    "        acts = []\n",
    "        rews = []\n",
    "        \n",
    "        s = env.reset()\n",
    "        d = False\n",
    "\n",
    "        while not d:\n",
    "            ab, ed = _preproc_ab(s[0], s[1]), \\\n",
    "                     _preproc_ab(s[-2], s[-1])\n",
    "            prob = policy.compute_prob(ab.unsqueeze(dim=0), ed.unsqueeze(dim=0)).squeeze()\n",
    "            prob /= prob.sum()\n",
    "            \n",
    "            action = np.random.choice(s[-1].size, p = prob.numpy(), size=1)\n",
    "\n",
    "            obss.append(_preproc(s))\n",
    "\n",
    "            s, r, d, _ = env.step(list(action))\n",
    "            A, b, c0, cuts_a, cuts_b = s\n",
    "            acts.append(action)\n",
    "            rews.append(r)\n",
    "            \n",
    "        rrecord.append(np.sum(rews))\n",
    "        \n",
    "        v_hat = discounted_rewards(rews, gamma)\n",
    "        As.append(pad_sequence([elem[0] for elem in obss], batch_first=True))\n",
    "        Bs.append(pad_sequence([elem[1] for elem in obss], batch_first=True))\n",
    "        Cs.append(pad_sequence([elem[2] for elem in obss], batch_first=True))\n",
    "        Es.append(pad_sequence([elem[-2] for elem in obss], batch_first=True))\n",
    "        Ds.append(pad_sequence([elem[-1] for elem in obss], batch_first=True))\n",
    "        \n",
    "        \n",
    "        ACTs.append(torch.tensor(acts))\n",
    "        VAL.append(v_hat)\n",
    "    \n",
    "\n",
    "    for a, b, e, d, v in zip(As, Bs, Es, Ds, VAL):\n",
    "        ab = torch.cat((a, b.unsqueeze(-1)), dim=-1)\n",
    "        ed = torch.cat((e, d.unsqueeze(-1)), dim=-1)\n",
    "        loss = baseline.train(ab, ed, v)\n",
    "        \n",
    "        \n",
    "    baseline.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # UPDATE\n",
    "    baseline.optimizer.step()\n",
    "    baseline.scheduler.step()\n",
    "        \n",
    "        \n",
    "    print(f'baseline loss: {loss.item()}')\n",
    "    \n",
    "    ADs = []\n",
    "    \n",
    "    for a, b, e, d, v in zip(As, Bs, Es, Ds, VAL):\n",
    "        ab = torch.cat((a, b.unsqueeze(-1)), dim=-1)\n",
    "        ed = torch.cat((e, d.unsqueeze(-1)), dim=-1)\n",
    "        ADs.append(val - baseline.compute_values(ab, ed))\n",
    "        \n",
    "    for a, b, e, d, acts, ads in zip(As, Bs, Es, Ds, ACTs, ADs):\n",
    "        ab = torch.cat((a, b.unsqueeze(-1)), dim=-1)\n",
    "        ed = torch.cat((e, d.unsqueeze(-1)), dim=-1)\n",
    "        loss = policy.train(ab, ed, acts, ads)\n",
    "        \n",
    "    policy.optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # UPDATE\n",
    "    policy.optimizer.step()\n",
    "    policy.scheduler.step()\n",
    "        \n",
    "    print(f'agent loss: {loss}')\n",
    "\n",
    "        \n",
    "    print(f'iteration: {ite}, training reward: {np.mean(rrecord[-numtrajs:])}')\n",
    "#     for ab_batch, ed_batch, v_hat in zip(ABs, EDs, VAL):\n",
    "#         loss = baseline.train(ab_batch, ed_batch, v_hat)\n",
    "#         print(f'baseline loss: {loss}')\n",
    "#     ADs = []\n",
    "#     for ab_batch, ed_batch, val in zip(ABs, EDs, VAL):\n",
    "#         ADs.append(val - baseline.compute_values(ab_batch, ed_batch))          \n",
    "#     for ab_batch, ed_batch, acts, ads in zip(ABs, EDs, ACTs, ADs):\n",
    "#         loss = policy.train(ab_batch, ed_batch, acts, ads)\n",
    "#         print(f'agent loss: {loss}')\n",
    "        \n",
    "#     print(f'iteration: {ite}, training reward: {rrecord[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ieor4575]",
   "language": "python",
   "name": "conda-env-ieor4575-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
