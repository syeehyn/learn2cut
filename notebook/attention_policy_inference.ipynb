{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from gymenv_v2 import make_multiple_env\n",
    "import json\n",
    "easy_config = {\n",
    "    \"load_dir\"        : '../instances/train_10_n60_m60',\n",
    "    \"idx_list\"        : list(range(10)),\n",
    "    \"timelimit\"       : 50,\n",
    "    \"reward_type\"     : 'obj'\n",
    "    }\n",
    "hard_config = {\n",
    "    \"load_dir\"        : '../instances/train_100_n60_m60',\n",
    "    \"idx_list\"        : list(range(99)),\n",
    "    \"timelimit\"       : 50,\n",
    "    \"reward_type\"     : 'obj'\n",
    "}\n",
    "test_config = {\n",
    "\"load_dir\" : '../instances/test_100_n60_m60',\n",
    "\"idx_list\" : list(range(99)),\n",
    "\"timelimit\" : 50,\n",
    "\"reward_type\" : 'obj'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "        'cnn_hidden': [8,16],\n",
    "        'rnn_hidden': 32,\n",
    "        'dropout': .3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.distributions import Categorical\n",
    "from src.attention_policyNet.policy import Policy\n",
    "from src.attention_policyNet.policy_roller import Observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, observer, model):\n",
    "        self.policy = model.eval()\n",
    "        self.observer=observer\n",
    "        self.rewards=[]\n",
    "    def select_action(self, state, obss):\n",
    "        probs = self.policy(state, obss)\n",
    "        action = probs.argmax()\n",
    "        return action.item()\n",
    "    def report_reward(self, reward, d):\n",
    "        self.rewards.append(reward)\n",
    "    def run_episode(self):\n",
    "        self.observer.run_episode(self)\n",
    "    def finish_episode(self):\n",
    "        rewards = self.rewards\n",
    "        reward = sum(rewards)\n",
    "        self.rewards = []\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = json.load(open('attention.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('attention_results.json', 'w') as f:\n",
    "    json.dump({}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = json.load(open('attention_results.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model_id in tqdm(models):\n",
    "    res = json.load(open('attention_results.json'))\n",
    "    if model_id not in res.keys():\n",
    "        model = Policy(60, model_config['cnn_hidden'], \n",
    "                            model_config['rnn_hidden'],\n",
    "                            model_config['dropout']\n",
    "                        )\n",
    "        model.load_state_dict(torch.load(f'../trained_models/{model_id}'))\n",
    "        result = {}\n",
    "        for env_config, env_name in zip([easy_config, hard_config, test_config], \\\n",
    "                                        ['easy_config', 'hard_config', 'test_config']):\n",
    "            observer = Observer(env_config)\n",
    "            agent = Agent(observer, model)\n",
    "            rewards = []\n",
    "            for iteration in range(12):\n",
    "                agent.run_episode()\n",
    "                reward = agent.finish_episode()\n",
    "                rewards.append(reward)\n",
    "            rewards = sorted(rewards)[1:-1]\n",
    "            reward = sum(rewards)/len(rewards)\n",
    "            result[env_name] = reward\n",
    "        res[model_id] = result\n",
    "    with open('attention_results.json', 'w') as f:\n",
    "        json.dump(res, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieor4575",
   "language": "python",
   "name": "ieor4575"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
